---
title: "Recruitment Funnel Analysis"
author: "Daniel Procter"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  html_document:
    theme: cosmo
    toc: true
    toc_float: true
    number_sections: true
    number_offset: 0
    fig_caption: true
    self_contained: true
output_file: "report.html"
---

```{r set up, include=FALSE}

# Install and load required packages (install if missing)
packages <- c(
  "tidyverse",
  "psych",
  "performance",
  "pROC",
  "knitr",
  "kableExtra",
  "scales",
  "broom",
  "ggthemes",
  "RColorBrewer",
  "gridExtra"
)
installed <- packages %in% row.names(installed.packages())
if (any(!installed)) {
  install.packages(packages[!installed])
}
lapply(packages, library, character.only = TRUE)

# knitr global chunk options
knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE,
  fig.align = "center", fig.width = 8, fig.height = 5, dpi = 150,
  out.width = "90%"
)

# Default categorical colour scales
scale_color_discrete <- function(...) ggplot2::scale_color_brewer(palette = "Set2", ...)
scale_fill_discrete <- function(...) ggplot2::scale_fill_brewer(palette = "Set2", ...)

# Stage order used in tables/plots
stage_order <- c("Application","Screening","Interview","Offer","Hired")

# Label helper
pct <- function(x, acc = 0.1) scales::percent(x, accuracy = acc)

# Avoid scientific notation
options(scipen = 999)  

```

## Introduction
This report explores a simulated recruitment dataset, with the aim of understanding how candidates move through the hiring funnel and what factors influence their chances of success. The analysis will focus on questions such as:

* How many candidates reach each stage, and where do the biggest drop-offs occur?
* Do recruiter performance or source of application affect outcomes?
* Do higher test scores improve the likelihood of being hired?
* Are some job roles or locations harder to fill than others?
* Which factors overall are most predictive of a candidate being hired?

The dataset tracks applicants through five stages: application, screening, interview, offer, and hire. For each candidate it includes:

* Recruiter `rec_id` – one of five recruiters.
* Job role `job_role` – four possible roles.
* Location `location` – four UK office locations.
* Source `source` – LinkedIn, job boards, or the company careers page.
* Test score `score` – a 0–100 score mimicking results from application tests (e.g., psychometric assessments).
* Stage flags `application`, `screening`, `interview`, `offer`, `hired`) – binary indicators of progression.

The simulation includes parameters to reflect real-world variation. Candidate scores differ by source, recruiters vary in closing effectiveness, and progression rates depend on both scores and source.

Although the dataset was created programmatically, the analysis is approached as if it were newly provided, with the aim of uncovering patterns and drivers of hiring success.


## Data Checks & Preparation
Before beginning the analysis, it is important to confirm that the dataset is properly structured and suitable for use. Although the data were simulated, it is treated as if it were newly provided, and a set of basic checks are applied to ensure consistency and integrity.

```{r initial checks, results='hide'}

# Loading dataset
df <- read.csv("../data/simulated_funnel_data.csv")

# Inspecting structure
str(df)

# Checking unique values in categorical columns
unique(df$rec_id)
unique(df$source)
unique(df$location)
unique(df$job_role)

# Storing factor levels
rec_levels <- c("R1","R2","R3","R4","R5")
source_levels <- c("LinkedIn","Job board","Careers page")
location_levels <- c("London","Bristol","Edinburgh","Manchester")
role_levels <- c("Software Engineer","HR Specialist","Data Analyst","Marketing Associate")

# Coercing column types
df <- df %>%
  mutate(rec_id = factor(rec_id, levels = rec_levels),
         source = factor(source, levels = source_levels),
         location = factor(location, levels = location_levels),
         job_role = factor(job_role, levels = role_levels))

```

The checks focused on the following points:

* Candidate IDs are unique
* Test scores fall within the expected range of 0–100
* Stage flags contain only values of 0 or 1
* The number of candidates decreases at each stage of the funnel
* No missing values are present

```{r logical checks}

# Stage columns
stage_cols <- c("application","screening","interview","offer","hired")

# Checking unique candidate IDs
unique_id_check <- anyDuplicated(df$cand_id) == 0

# Checking score range (expected 0–100)
score_range <- range(df$score, na.rm = TRUE)
score_check <- score_range[1] >= 0 && score_range[2] <= 100

# Checking stage values in {0,1}
stage_value_check <- all(sapply(df[stage_cols], function(x) all(x %in% c(0,1))))

# Checking funnel monotonicity (totals non-increasing)
stage_totals   <- colSums(df[stage_cols])
stage_counts_check <- all(diff(stage_totals) <= 0)

# Checking for missing values
na_total <- sum(is.na(df))
na_check <- na_total <= 0

```

The table below summarises the results of these checks.

```{r summary table}

# Shape
n_rows <- nrow(df); n_cols <- ncol(df)

# Compact, professional summary
checks_summary <- tibble(
  Check = c("Dataset shape",
            "Unique candidate IDs",
            "Score range within 0–100",
            "Stage values restricted to {0,1}",
            "Funnel monotonicity (stage counts decrease)",
            "Missing values"), 
  
  Summary = c(
    paste(n_rows, "rows ×", n_cols, "columns"),
    ifelse(unique_id_check, "No duplicates found", "Duplicates detected"),
    paste0("Observed range: ", paste(score_range, collapse = "–")),
    ifelse(stage_value_check, "All valid", "Invalid values present"),
    ifelse(all(diff(stage_totals) <= 0), "All stages monotonic", "Non-monotonic stage counts"),
    ifelse(na_total == 0, "None detected", paste(na_total, "missing values"))
  )
)

# Nicely formatted table
knitr::kable(checks_summary,
             caption = "Summary of Data Quality Checks",
             col.names = c("Check", "Summary"),
             align = "l") %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "bordered"), position = "center", full_width = TRUE)

```

The dataset contains 2,500 rows and 12 columns, with no missing values. Candidate identifiers are unique, scores and dates fall within the expected ranges, and progression through the funnel follows the correct pattern.

Finally, the first few rows of the dataset are displayed below.

```{r top rows}

# Print top rows
kable(head(df, 5), align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center", full_width = FALSE) %>%
  column_spec(1:ncol(df), width = "auto", extra_css = "white-space: nowrap;") %>%
  scroll_box(width = "100%")

```


## Analysis
This section analyses candidate progression through the recruitment process and explores the key factors influencing hiring outcomes.

It begins with an overview of the funnel and key variables, followed by deeper analysis of how scores, recruiters, sources, roles, and locations relate to hiring success. Together, these analyses provide the foundation for the predictive modelling in Section 4.

### Overall Funnel Counts & Conversion
This section examines how candidates progress through each stage of the recruitment process, focusing on overall volumes and conversion rates. These metrics highlight where the largest drop-offs occur and how efficiently applicants advance through the funnel.

```{r funnel counts}

# Number of candidates
n_cand <- nrow(df)

# Counts per stage
stage_counts <- colSums(df[stage_cols])

# Table 1: share of total applicants
tbl_share <- tibble(Stage = stage_order,
                    Count = stage_counts,
                    Percentage = pct(stage_counts / n_cand))

# Table 2: conversion from previous stage
tbl_conv <- tibble(Stage = stage_order,
                   Conversion = c(NA, stage_counts[-1] / head(stage_counts, -1))) %>%
  mutate(Conversion = ifelse(is.na(Conversion), "--", pct(Conversion)))

```

```{r share table}

# Printing table
kable(tbl_share, caption = "Share of Total Applicants", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center")

```

```{r funnel plot}

# Setting order
tbl_share$Stage <- factor(tbl_share$Stage, levels = stage_order)

# Funnel plot
ggplot(tbl_share, aes(x = Stage, y = Count, fill = Stage)) +
  geom_col(color = "white", linewidth = 0.5) +
  geom_text(aes(label = Count), vjust = -0.3, size = 3.5, color = "black") +
  scale_fill_economist() +
  scale_y_continuous(limits = c(0, 2500), expand = expansion(mult = c(0, 0.08))) +
  labs(title = "Applicant Volume by Stage", x = NULL, y = "Number of Candidates") +
  theme_economist() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 13),
        panel.grid.minor = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "none",
        axis.title.y = element_text(margin = margin(r = 8)))


```

```{r conversion table}

# Printing table
kable(tbl_conv, caption = "Conversion from Previous Stage", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center")

```

```{r conversion plot}

# Converting table
tbl_conv_plot <- tbl_conv %>%
  mutate(Stage = factor(Stage, levels = stage_order),
         Conversion = suppressWarnings(as.numeric(gsub("%", "", Conversion)))) %>%
  filter(Stage != "Application")

# Conversion plot
ggplot(tbl_conv_plot, aes(x = Stage, y = Conversion, fill = Stage)) +
  geom_col(color = "white", linewidth = 0.5) +
  geom_text(aes(label = pct(Conversion / 100, acc = 0.1)), vjust = -0.3, size = 3.5, color = "black") +
  scale_fill_economist() +
  scale_y_continuous(limits = c(0, 100), expand = expansion(mult = c(0, 0.08))) +
  labs(title = "Conversion Rate by Stage", x = NULL, y = "Conversion (%)") +
  theme_economist() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 13),
        panel.grid.minor = element_blank(),
        axis.ticks = element_blank(),
        legend.position = "none",
        axis.title.y = element_text(margin = margin(r = 8)))

```

Out of 2,500 applicants, only 214 were ultimately hired (8.6%). The largest attrition occurs between the Interview and Offer stages, with just 28.7% progressing. Earlier filters at screening and interview also remove substantial proportions of candidates. In contrast, the high Offer-to-Hire conversion (81.1%) suggests that once candidates reach the final stage, selection and acceptance are strong.

The funnel metrics show how efficiently candidates move through each stage, but not the factors behind those outcomes. The following section explores candidate test scores to understand performance patterns that may influence progression.


### Assessment Scores


#### Summary and Distributions
Each candidate received a test score between 0 and 100, reflecting their performance on an assessment used during the application stage. This section examines how these scores are distributed across applicants and whether higher scores are linked to greater success in progressing through the recruitment funnel.

```{r score summary table}

# Summary table
tbl_scores <- describe(df$score) %>%
  select(mean, sd, median, min, max, range, se) %>%
  mutate(across(c(mean, sd, se), ~ round(.x, 2))) %>%
  rename_with(~ tools::toTitleCase(.x)) %>%
  as_tibble()

# Printing table
kable(tbl_scores, caption = "Summary Statistics for Candidate Test Scores", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center")

```

The average score of 63.42 suggests moderate overall performance, with a standard deviation of 13.94 indicating clear variation between applicants. The wide range of results (20–100) shows the assessment distinguishes well between weaker and stronger performers, supporting its value as an effective screening tool. The following histogram visualises this distribution.

```{r score histogram}

# Histogram
ggplot(df, aes(x = score)) +
  geom_histogram(aes(y = after_stat(count), fill = after_stat(count)),
                 binwidth = 1, color = "white", boundary = 0, alpha = 0.9) +
  scale_y_continuous(limits = c(0, 100), expand = expansion(mult = c(0, 0.02))) +
  labs(title = "Distribution of Candidate Test Scores", x = "Test Score", y = "Count") +
  theme_economist() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 13),
    panel.grid.minor = element_blank(),
    axis.ticks = element_blank(),
    legend.position = "none",
    axis.text.x = element_text(margin = margin(t = 5)),
    axis.title.x = element_text(margin = margin(t = 10)),
    axis.title.y = element_text(margin = margin(r = 10))  # move y-axis label back
  )

```

The distribution of candidate test scores appears roughly normal, indicating a balanced spread of scores without strong skew.

While the assessment effectively differentiates candidate ability, it is also important to examine whether higher scores lead to greater progression and eventual hiring.


#### Score and Hiring Success
This analysis explores whether higher scores correspond to a greater likelihood of being hired, and more broadly, how candidates with different score levels progress through the recruitment funnel. A logistic regression model is used to quantify this relationship, supported by descriptive comparisons across score bands.

```{r score logistic regression}

# Logistic regression
score_logreg <- glm(hired ~ score, data = df, family = "binomial")

# Model components
coef_summary <- summary(score_logreg)$coefficients
coef <- coef_summary["score", "Estimate"]
pval <- coef_summary["score", "Pr(>|z|)"]
odds_ratio <- exp(coef)
pct_increase <- (odds_ratio - 1) * 100
r2_value <- r2_nagelkerke(score_logreg)

# Table
tbl_logreg <- tibble(
  Predictor = "Score",
  Coefficient = round(coef, 3),
  `P-value` = round(pval, 4),
  `Odds Ratio` = round(odds_ratio, 3),
  `Odds Increase (%)` = round(pct_increase, 1),
  `Nagelkerke R2` = round(r2_value, 3)
 )

# Printing table
kable(tbl_logreg, caption = "Assessment Score Predicting Hiring Success", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center")

```

The regression results show a clear positive relationship between assessment score and hiring success. For each one-point increase in score, a candidate has about a 5.6 percent greater likelihood of being hired, and the effect is statistically significant (p < 0.001). The model’s Nagelkerke R² of 0.089 indicates that assessment scores explain around 9 percent of the variation in hiring outcomes, which is reasonable given that final decisions also depend on several other factors.

```{r logistic regression curve, warnings = FALSE}

# Predicted probabilities
score_pred_prob <- tibble(score = df$score,
                          pred_prob = predict(score_logreg, type = "response"))

# Plotting curve
ggplot(score_pred_prob, aes(x = score, y = pred_prob)) +
  stat_smooth(method = "glm", method.args = list(family = binomial()), se = TRUE, fullrange = TRUE) +
  labs(title = "Hire Probability vs Score", x = "Assessment Score", y = "Predicted Probability") +
  scale_y_continuous(limits = c(0, 0.5), expand = expansion(mult = c(0, 0.05)), labels = pct) +
  theme_economist() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 13), 
        panel.grid.minor = element_blank(), 
        legend.position = "none",
        axis.title.y = element_text(margin = margin(r = 8)))

```

The above visual shows how the logistic regression curve rises upwards. The model predicts a higher probability of being hired as assessment scores increase. 

To look deeper into how candidates at different performance levels progress through the recruitment process, scores are grouped into bands to compare progression rates across stages.

```{r score bands}

# Score bands  
df <- df %>%
  mutate(score_band = cut(score, breaks = c(0, 50, 65, 80, 101), 
                          labels = c("Low", "Moderate", "High", "Very High"), right = FALSE)) %>%
  relocate(score_band, .after = score)

# Score interpretation
tbl_score_levels <- tibble(
  `Score Range` = c("0–49", "50–64", "65–79", "80–100"),
  Interpretation = c("Low", "Moderate", "High", "Very High"))

# Print table
kable(tbl_score_levels, caption = "Score Band Interpretation", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center")

```

```{r grouped bar chart}

# Pivoting data
tbl_band_stage <- df %>%
  group_by(score_band) %>%
  summarise(across(c(screening, interview, offer, hired),
                   ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(-score_band, names_to = "Stage", values_to = "Proportion") %>%
  mutate(Percentage = pct(Proportion)) %>%
  rename(`Score Band` = score_band)

# Enforcing stage order
stage_order_plot <- c("screening","interview","offer","hired")

# Grouped bar chart
ggplot(tbl_band_stage, aes(Stage, Proportion, fill = `Score Band`)) +
  geom_col(position = position_dodge(width = 0.72)) +
  scale_x_discrete(limits = stage_order_plot) + 
  scale_y_continuous(labels = pct, limits = c(0, 1), expand = expansion(mult = c(0, 0.02))) +
  scale_fill_economist(name = NULL) +
  labs(title = "Stage progression by score band", x = NULL, y = "Proportion") +
  theme_economist() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 13),
        panel.grid.minor = element_blank(),
        axis.ticks = element_blank(),
        legend.title = element_blank(),
        legend.text = element_text(size = 10),
        legend.key.size = grid::unit(10, "pt"),
        axis.title.y = element_text(margin = margin(r = 8))
  )

```

The results reveal a clear stepwise pattern, with progression rates increasing steadily across higher score bands. Candidates in the Very High band perform best at every stage, with 94% passing screening and around 21% ultimately hired. In contrast, only 48% of Low scorers pass the screening stage, and just 3% are eventually hired.

The largest drop-off occurs between the screening and interview stages, particularly among Low and Moderate scorers, where progression rates roughly halve. Beyond this point, High and Very High scorers continue to advance at higher and more consistent rates, indicating that assessment performance exerts its strongest influence during the early filtering stages.

Overall, this pattern suggests that the assessment effectively distinguishes candidate quality at the outset, providing a strong early indicator of hiring potential. Later stages likely reflect broader evaluation factors beyond test performance.


#### Score by Recruiter
Candidate scores are compared across recruiters to see whether differences in recruiter performance may reflect the quality of applicants in their pipelines.

```{r score by recruiter summary stats}

# Summary table
tbl_rec_scores <- describeBy(df$score, group = df$rec_id, mat = TRUE) %>%
  select(group1, n, mean, sd, median, min, max, range, se) %>%
  mutate(across(c(mean, sd, se), ~ round(.x, 2))) %>%
  rename(Recruiter = group1) %>%
  rename_with(~ tools::toTitleCase(.x)) %>%
  as_tibble()

# Printing table
kable(tbl_rec_scores,
      caption = "Summary Statistics for Candidate Scores by Recruiter",
      align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"),
                position = "center")
 
```

```{r score by recruiter boxplots}

# Boxplot
ggplot(df, aes(x = rec_id, y = score, fill = rec_id)) +
  geom_boxplot(alpha = 0.8, outlier.shape = 21, outlier.size = 2, outlier.alpha = 0.5, width = 0.7) +
  labs(title = "Distribution of Candidate Scores by Recruiter", x = "Recruiter", y = "Candidate Score") +
  scale_fill_economist(name = NULL) +
  theme_economist() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 13),
    axis.text.x = element_text(angle = 30, size = 9, vjust = 1.5),
    axis.title.y = element_text(margin = margin(r = 10)), 
    panel.grid.minor = element_blank(),
    legend.position = "none"
  )

```

The summary statistics show that average candidate scores are very similar across recruiters, with only small differences between them. The boxplots also suggest a similar spread of scores, indicating little variation in candidate quality between recruiters.

To confirm this, an ANOVA test will be run to check whether any of these small differences in mean scores are statistically significant.

```{r score by recruiter ANOVA}

# ANOVA
anova_rec <- aov(score ~ rec_id, data = df)

# Table
anova_rec_tbl <- tibble(
  `R1 mean` = round(mean(df$score[df$rec_id == "R1"]), 2),
  `R2 mean` = round(mean(df$score[df$rec_id == "R2"]), 2),
  `R3 mean` = round(mean(df$score[df$rec_id == "R3"]), 2),
  `R4 mean` = round(mean(df$score[df$rec_id == "R4"]), 2),
  `R5 mean` = round(mean(df$score[df$rec_id == "R5"]), 2),
  `F` = round(summary(anova_rec)[[1]][["F value"]][1], 2),
  df = summary(anova_rec)[[1]][["Df"]][1],
  p = round(summary(anova_rec)[[1]][["Pr(>F)"]][1], 3)
)

# Printing table
kable(anova_rec_tbl, caption = "Score by Recruiter ANOVA Results", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center", full_width = TRUE) %>%
  column_spec(1:5, width = "6em") %>%
  column_spec(6:8, width = "4em")  

```

The ANOVA results show no significant difference in average candidate scores between recruiters, F(4, 2495) = 2.06, p = 0.083. This indicates that candidate quality is largely consistent across recruiters.


#### Score by Applicant Source
Candidate scores are compared across different application sources to assess whether certain channels attract higher-scoring applicants. This helps to identify which sourcing methods are bringing in stronger candidates.

```{r score by source summary stats}

# Summary table
tbl_src_scores <- describeBy(df$score, group = df$source, mat = TRUE) %>%
  select(group1, n, mean, sd, median, min, max, range, se) %>%
  mutate(across(c(mean, sd, se), ~ round(.x, 2))) %>%
  rename(`Source` = group1) %>%
  rename_with(~ tools::toTitleCase(.x)) %>%
  as_tibble()

# Printing table
kable(tbl_src_scores,
      caption = "Summary Statistics for Candidate Scores by Source",
      align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center")

```

```{r score by source boxplots}

# Boxplots
ggplot(df, aes(x = source, y = score, fill = source)) +
  geom_boxplot(alpha = 0.8, outlier.shape = 21, outlier.size = 2, outlier.alpha = 0.5, width = 0.7) +
  labs(title = "Distribution of Candidate Scores by Source", x = "Source", y = "Candidate Score") +
  scale_fill_economist(name = NULL) +
  theme_economist() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 13),
    axis.text.x = element_text(hjust = 0.5, vjust = 1.5, size = 9),
    axis.title.y = element_text(margin = margin(r = 10)),
    panel.grid.minor = element_blank(),
    legend.position = "none"
  )

```

The average candidate scores differ notably across application sources. Candidates applying through LinkedIn have the highest average score (70.2), followed by those from the Careers page (59.7) and Job boards (54.5). The spread of scores is similar across all sources, though LinkedIn candidates tend to perform stronger overall. This pattern suggests that LinkedIn attracts higher-quality applicants on average, while Job boards yield a wider range of candidates with generally lower assessment performance.

To confirm whether the differences in mean candidate scores between sources are statistically significant, an ANOVA test was run to compare average scores across all application sources.

```{r score by source ANOVA}

# ANOVA
anova_src <- aov(score ~ source, data = df)

# Table
anova_src_tbl <- tibble(
  `LinkedIn mean` = round(mean(df$score[df$source == "LinkedIn"]), 2),
  `Job board mean` = round(mean(df$score[df$source == "Job board"]), 2),
  `Careers page mean` = round(mean(df$score[df$source == "Careers page"]), 2),
  `F` = round(summary(anova_src)[[1]][["F value"]][1], 2),
  df = summary(anova_src)[[1]][["Df"]][1],
  p = round(summary(anova_src)[[1]][["Pr(>F)"]][1], 3)
)

# Printing table
kable(anova_src_tbl, caption = "Score by Source ANOVA Results", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center", full_width = TRUE) %>%
  column_spec(1:3, width = "6em") %>%
  column_spec(4:6, width = "4em")  

```

The ANOVA results show a statistically significant difference in mean candidate scores between sources, F(2, 2497) = 434.58, p < 0.001. Candidates from LinkedIn scored substantially higher on average than those from the Careers page or Job boards, indicating that candidate quality varies considerably by application source. Given the size of these differences, post-hoc tests are not strictly necessary, as the summary statistics already make the pattern clear.


#### Score by Job Role
Candidate scores are compared across different job roles to identify whether certain positions tend to attract higher-scoring applicants. This helps to understand if candidate quality varies by the type of role being applied for.

```{r score by role summary stats}

# Summary table
tbl_role_scores <- describeBy(df$score, group = df$job_role, mat = TRUE) %>%
  select(group1, n, mean, sd, median, min, max, range, se) %>%
  mutate(across(c(mean, sd, se), ~ round(.x, 2))) %>%
  rename(`Job Role` = group1) %>%
  rename_with(~ tools::toTitleCase(.x)) %>%
  as_tibble()

# Printing table
kable(tbl_role_scores,
      caption = "Summary Statistics for Candidate Scores by Job Role",
      align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center")

```

```{r score by role boxplots}

# Boxplots
ggplot(df, aes(x = job_role, y = score, fill = job_role)) +
  geom_boxplot(alpha = 0.8, outlier.shape = 21, outlier.size = 2, outlier.alpha = 0.5, width = 0.7) +
  labs(title = "Distribution of Candidate Scores by Job Role", x = "Job Role", y = "Candidate Score") +
  scale_fill_economist(name = NULL) +
  theme_economist() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 13),
    axis.text.x = element_text(hjust = 0.5, vjust = 1.5, size = 9),
    axis.title.y = element_text(margin = margin(r = 10)),
    panel.grid.minor = element_blank(),
    legend.position = "none"
  )

```

The average candidate scores are very similar across job roles, ranging between 62.9 and 64.5. This suggests that overall candidate quality is consistent regardless of the role applied for. The Marketing Associate role shows slightly less variation in scores, likely due to its smaller sample size. Interestingly, while the average score for Marketing Associate candidates is marginally higher than the others, their maximum score of 87 indicates that the very highest-performing applicants are not applying for this role.

To confirm that overall candidate quality is consistent across roles, an ANOVA test will be run to check whether these small differences in mean scores are statistically significant.

```{r score by job role ANOVA}

# ANOVA
anova_role <- aov(score ~ job_role, data = df)

# Table
anova_role_tbl <- tibble(
  `SE mean` = round(mean(df$score[df$job_role == "Software Engineer"]), 2),
  `HR mean` = round(mean(df$score[df$job_role == "HR Specialist"]), 2),
  `DA mean` = round(mean(df$score[df$job_role == "Data Analyst"]), 2),
  `MA mean` = round(mean(df$score[df$job_role == "Marketing Associate"]), 2),
  `F` = round(summary(anova_role)[[1]][["F value"]][1], 2),
  df = summary(anova_role)[[1]][["Df"]][1],
  p = round(summary(anova_role)[[1]][["Pr(>F)"]][1], 3)
)

# Printing table
kable(anova_role_tbl, caption = "Score by Job Role ANOVA Results", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center", full_width = TRUE) %>%
  column_spec(1:4, width = "6em") %>%
  column_spec(5:7, width = "4em")  

```

The ANOVA results show no significant difference in average candidate scores between job roles, F(3, 2496) = 1.1, p = 0.349. This indicates that candidate quality is consistent across roles.


#### Score by Location
Candidate scores are compared across different office locations to assess whether candidate quality varies by region.

```{r score by location summary stats}

# Summary table
tbl_loc_scores <- describeBy(df$score, group = df$location, mat = TRUE) %>%
  select(group1, n, mean, sd, median, min, max, range, se) %>%
  mutate(across(c(mean, sd, se), ~ round(.x, 2))) %>%
  rename(`Job Role` = group1) %>%
  rename_with(~ tools::toTitleCase(.x)) %>%
  as_tibble()

# Printing table
kable(tbl_loc_scores,
      caption = "Summary Statistics for Candidate Scores by Location",
      align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center")

```

```{r score by location boxplots}

# Boxplots
ggplot(df, aes(x = location, y = score, fill = location)) +
  geom_boxplot(alpha = 0.8, outlier.shape = 21, outlier.size = 2, outlier.alpha = 0.5, width = 0.7) +
  labs(title = "Distribution of Candidate Scores by Job Role", x = "Location", y = "Candidate Score") +
  scale_fill_economist(name = NULL) +
  theme_economist() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 13),
    axis.text.x = element_text(hjust = 0.5, vjust = 1.5, size = 9),
    axis.title.y = element_text(margin = margin(r = 10)),
    panel.grid.minor = element_blank(),
    legend.position = "none"
  )

```

The average candidate scores are very similar across locations, ranging from 62.8 to 64.1. This indicates that overall candidate quality is consistent across regions. The spread of scores is also comparable between locations, suggesting that assessment results are not influenced by geographic factors.

To confirm that these small differences in mean scores between locations are not statistically significant, an ANOVA test will be run to compare average candidate scores across all office locations.

```{r score by location ANOVA}

# ANOVA
anova_loc <- aov(score ~ location, data = df)

# Table
anova_loc_tbl <- tibble(
  `London mean` = round(mean(df$score[df$location == "London"]), 2),
  `Bristol mean` = round(mean(df$score[df$location == "Bristol"]), 2),
  `Edinburgh mean` = round(mean(df$score[df$location == "Edinburgh"]), 2),
  `Manchester mean` = round(mean(df$score[df$location == "Manchester"]), 2),
  `F` = round(summary(anova_loc)[[1]][["F value"]][1], 2),
  df = summary(anova_loc)[[1]][["Df"]][1],
  p = round(summary(anova_loc)[[1]][["Pr(>F)"]][1], 3)
)

# Printing table
kable(anova_loc_tbl, caption = "Score by Location ANOVA Results", align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"), position = "center", full_width = TRUE) %>%
  column_spec(1:4, width = "6em") %>%
  column_spec(5:7, width = "4em")  

```

The ANOVA results show no significant difference in average candidate scores between locations, F(3, 2496) = 1.24, p = 0.292. This indicates that candidate quality is consistent across regions.

#### Score Analysis Summary
Assessment score is a key predictor of hiring success, with higher-scoring candidates significantly more likely to be hired. The influence of score is strongest during the early filtering stages, where higher performers progress through screening and interview stages at notably higher rates.

Average scores do not differ meaningfully between recruiters, job roles, or locations, indicating consistent candidate quality across these groups. However, significant differences are observed between application sources, with candidates applying through LinkedIn achieving the highest average scores.

Overall, assessment score effectively differentiates candidate quality early in the recruitment process and provides a strong indicator of hiring potential.


### Recruiter Performance


#### Overview of Recruiter Activity


#### Stage Conversion by Recruiter

#### Recruiter by Source

#### Recruiter by Location

#### Recruiter by Role
 
### Job Role Performance

#### Volume and Hire Rate by Role

#### Stage Conversion by Role

### Location Performance

#### Applicant and Hire Volume by Location

#### Stage Conversion by Location

### Predictive Modelling

#### Multiple Logistic Regression

#### Decision Tree

#### Random Forest

#### Model Comparison

## Summary